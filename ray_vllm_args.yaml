# заменить по желанию на:
# "Qwen/Qwen2.5-7B-Instruct-GPTQ-Int8"
# model: "Qwen/Qwen2.5-0.5B-Instruct"
model: "Qwen/Qwen3-8B-FP8"

# "Qwen/Qwen2.5-14B-Instruct-GPTQ-Int8"
# "Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8"
# served_model_name: "Qwen/Qwen2.5-14B-Instruct-1M"

gpu_memory_utilization: 0.90 # каждый гпу будет загружен на 70%. Больше - лучше! Допустимый предел 0 - 1 Подбирать пока не заработает
distributed_executor_backend: ray
tensor_parallel_size: 1 # количество гпу, на которых будет крутиться модель параллельно
pipeline_parallel_size: 2
max_model_len: 10000
# quantization: "gptq"
# seed: 42
# use_v2_block_manager: true # depr
api_key: "NYXV2sS3PLDYLbC"
enable_chunked_prefill: true
max_num_batched_tokens: 2048
# hf_overrides: '{"local_files_only": true}'
swap_space: 2 # int: размер подкачки в ram (tensor_parallel_size * swap_space) = общий объём подкачки (можно уменьшить)
# preemption_mode: swap
# cpu_offload_gb: 3
# dtype: half
# enforce_eager: True

enable_reasoning: true # Enables reasoning mode for the model
reasoning_parser: deepseek_r1 # Specifies the parser to use for reasoning
enable_auto_tool_choice: true
tool_call_parser: hermes

kv_transfer_config: '{"kv_connector":"LMCacheConnectorV1", "kv_role":"kv_both"}'
